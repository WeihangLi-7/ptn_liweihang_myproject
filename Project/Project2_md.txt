# Project 2. PurZ/PurZ0/PurA 同源序列搜索及 profile hmm 的建立

###### Z 基因组，即 ZTCG 基因组，在基因组中 Z 完全取代了 A。目前已知几百种噬菌体具有 Z基因组。Z 基因组的生物合成通路在 2021 年被两个研究团队发现（Science, 2021,372(6541):512-516. Science. 2021, 372(6541):516-520）。在 Z 基因组生物合成通路中，PurZ 是一个关键蛋白，它是嘌呤核苷合成通路中关键蛋白 PurA 的同源物。PurZ 和 PurA最关键的区别，在 PurA 中参与催化的 Asp13 （按 E coli PurA 的序列编号）被 Ser 所取代。 后续工作中，一种 PurZ 的变体 PurZ0 被发现 （Nat Microbiol. 2023 Jul;8(7):1330-1338.），它是 PurA 到 PurZ 进化的中间体。

##### （1） 从文献/UniProt/PDB 出发，找出五条 PurZ 序列，五条 PurZ0 序列，五条 PurA 序列。分别提交名为 PurZ.fasta，PurZ0.fasta 和 PurA.fasta 的文件。

- PurZ：

![截屏2025-03-24 21.26.05](/Users/liweihang/Library/Application Support/typora-user-images/截屏2025-03-24 21.26.05.png)

- PurZ0（蓝色下滑线标出的ID为PurZ0的Uniprot ID）:

##### ![截屏2025-03-24 21.33.08](/Users/liweihang/Library/Application Support/typora-user-images/截屏2025-03-24 21.33.08.png)

- PurA：下载图中勾选的PurA
- ![截屏2025-03-24 21.51.11](/Users/liweihang/Library/Application Support/typora-user-images/截屏2025-03-24 21.51.11.png)

##### （2） 请尝试在云桌面上本地安装 BLAST。按顺序记录下来你安装过程中的每一个命令，并提交这个命令集合文件。下载 nr 库，从 PurZ0.fasta 中选一条 PurZ0 序列作为查询序列，使用本地安装的 BLASTp 搜索 nr 库来获取库中所有 PurZ0 序列（注意不要在结果中混入 PurA 或 PurZ， 阐述你如何实现这一点） 。你可以找到多少条？分别来自什么物种？提交一个 Excel 文件，表头为 NCBI Accession，物种， coverage(alignment length/length of query)， seqid (aka pident)， E-value， bit score， fasta序列。为了获取 Excel 的内容， 你选择了 BLAST 的哪种输出格式？

**本地安装BLAST**：

```bash
conda create -n BT1051 python=3.12 #Create an environment
conda activate BT1051
conda install bioconda::blast
```

**下载nr库**(nr库过大，后续使用服务器做)

```
conda install wget
wget https://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz
```

1. 把需要比对的序列上传给服务器，进行序列比对：

   ```bash
   (BT1051) liweihang@Mac-3 Project2 % scp -P 22112 /Users/liweihang/BT1051/Project2/Seleted_PurZ0.fa guest1@10.15.50.100:/public/home/guest1/compbio_2025/liwh/
   ```

   ```bash
   (liwh) [guest1@mgt01 liwh]$ -query Seleted _PurZ0.fa -db /share/database/ncbi_nr/nr -out q2_blast_results.txt -evalue 1e-5 -num_threads 10 -outfmt "6 sacc staxid qcovs pident evalue bitscore sseq"
   ```

   比对后，提取序列为Fasta格式：

   ```bash
   (BT1051) liweihang@Mac-3 2_ % awk '{print ">"$1"\n"$7}' q2_blast_results.txt > q2_sequences.fasta
   ```

2. 如何实现在结果中不混入PurA或PurZ？：

根据文献Nat Microbiol. 2023 Jul;8(7):1330-1338. PurZ0的Key residues为以下三个氨基酸：

```
ProteinID：>tr|A0A7L7SI10|A0A7L7SI10_9CAUD  (358 氨基酸)
14S,243I,305D#这三个氨基酸在文献中标记为15S，244I和306D，可能是比对之后的结果。已打开该文件进行核对。
```

可以以这条蛋白为模板进行标齐，取14，243，305位的氨基酸，如果这三位分别为Serine(S),Isoleucine(I),Aspartic Acid(D)即认为是PurZ0而非PurA或PurZ。

```python
# 读取比对文件并提取所需位置的氨基酸
def extract_amino_acids(file_path, positions):
    with open(file_path, 'r') as f:
        lines = f.readlines()
    
    output = []
    seq = ""
    for line in lines:
        if line.startswith(">"):  # 处理ID行
            if seq:
                # 处理之前的序列，提取位置
                selected_aa = [seq[p - 1] if p <= len(seq) else '-' for p in positions]
                output.append([header, *selected_aa])
            # 获取新的ID
            header = line.strip().split()[0][1:]  # 获取序列的ID
            seq = ""  # 清空序列
        else:
            seq += line.strip()  # 将序列合并到一起
            
    # 处理最后一个序列
    if seq:
        selected_aa = [seq[p - 1] if p <= len(seq) else '-' for p in positions]
        output.append([header, *selected_aa])

    return output

# 目标位置
positions = [132, 707, 810]
file_path = 'final_aligned.fa'

# 获取结果
result = extract_amino_acids(file_path, positions)

# 输出结果
for entry in result:
    print("\t".join(entry))
Results:
  比对后的关键位置：S14=13, I243=347, D305=476
```

```python
# 读取比对文件并提取所需位置的氨基酸，做判断后输出ID并统计保留与剔除的数量
def extract_amino_acids(file_path, positions):
    with open(file_path, 'r') as f:
        lines = f.readlines()
    
    kept_ids = []
    discarded_ids = []
    seq = ""
    for line in lines:
        if line.startswith(">"):  # 处理ID行
            if seq:
                # 处理之前的序列，提取位置
                selected_aa = [seq[p - 1] if p <= len(seq) else '-' for p in positions]
                # 判断这三个位置是否为 S, I, D
                if all(aa in ['S', 'I', 'D'] for aa in selected_aa):
                    kept_ids.append(header)
                else:
                    discarded_ids.append(header)
            # 获取新的ID
            header = line.strip().split()[0][1:]  # 获取序列的ID
            seq = ""  # 清空序列
        else:
            seq += line.strip()  # 将序列合并到一起
    
    # 处理最后一个序列
    if seq:
        selected_aa = [seq[p - 1] if p <= len(seq) else '-' for p in positions]
        # 判断这三个位置是否为 S, I, D
        if all(aa in ['S', 'I', 'D'] for aa in selected_aa):
            kept_ids.append(header)
        else:
            discarded_ids.append(header)

    return kept_ids, discarded_ids

# 目标位置
positions = [14,348 , 477]
file_path = '/Users/liweihang/BT1051/Project2/2_/q2_aligned.fasta'

# 获取结果
kept_ids, discarded_ids = extract_amino_acids(file_path, positions)

# 输出结果到txt文件
with open('filtered_ids.txt', 'w') as output_file:
    output_file.write("Kept IDs:\n")
    for entry in kept_ids:
        output_file.write(f"{entry}\n")
    
    output_file.write("\nDiscarded IDs:\n")
    for entry in discarded_ids:
        output_file.write(f"{entry}\n")

# 输出保留和剔除的数量
print(f"Total kept IDs: {len(kept_ids)}")
print(f"Total discarded IDs: {len(discarded_ids)}")
Results:
Total kept IDs: 228
Total discarded IDs: 272
```

得到过滤后的文件：q2_purz0_filtered.fa

```python
from Bio import SeqIO

# 1. 读取 filtered_ids.txt 获取要保留的 ID
with open("filtered_ids.txt", "r") as f:
    kept_ids = [line.strip() for line in f.readlines()[1:]]  # 跳过首行 "Kept IDs:"

# 2. 过滤 potential_purz0.fa，仅保留匹配的序列
input_fasta = "/Users/liweihang/BT1051/Project2/2_/q2_sequences.fasta"
output_fasta = "q2_purz0_filtered.fa"

count = 0
with open(output_fasta, "w") as out_f:
    for record in SeqIO.parse(input_fasta, "fasta"):
        if record.id in kept_ids:
            SeqIO.write(record, out_f, "fasta")
            count += 1

print(f"已提取 {count} 条序列到 {output_fasta}")
Results:
 已提取 228 条序列到 q2_purz0_filtered.fa
```

接下来把信息整合，得到去重后的excel表：

```python
import pandas as pd

# 读取 BLAST 结果文件
blast_results = pd.read_csv('/Users/liweihang/BT1051/Project2/2_/q2_blast_results.txt', sep='\t', header=None)
blast_results.columns = ['sacc', 'staxid', 'qcovs', 'pident', 'evalue', 'bitscore', 'sseq']

# 读取 species.txt
species_map = {}
with open('/Users/liweihang/BT1051/Project2/2_/species.txt') as f:
    for line in f:
        taxid, species = line.strip().split('\t')
        species_map[taxid] = species

# 读取 FASTA 文件
fasta_dict = {}
with open('/Users/liweihang/BT1051/Project2/2_/q2_purz0_filtered.fa') as f:
    lines = f.readlines()
    for i in range(0, len(lines), 2):
        seq_id = lines[i].strip().lstrip('>')
        seq = lines[i + 1].strip()
        fasta_dict[seq_id] = seq

# 生成最终的数据框
final_data = []
for _, row in blast_results.iterrows():
    taxid = str(row['staxid'])
    if taxid in species_map and row['sacc'] in fasta_dict:
        final_data.append([
            row['sacc'],
            species_map[taxid],
            row['qcovs'],
            row['pident'],
            row['evalue'],
            row['bitscore'],
            fasta_dict[row['sacc']]
        ])

# 创建 DataFrame 并保存为 Excel
final_df = pd.DataFrame(final_data, columns=['NCBI Accession', '物种', 'coverage', 'seqid', 'E-value', 'bitscore', 'fasta序列'])
final_df.to_excel('/Users/liweihang/BT1051/Project2/2_/final_output.xlsx', index=False)
import pandas as pd

# Path to the CSV file and FASTA file
csv_file = '/Users/liweihang/BT1051/Project2/2_/blast_results_with_species.csv'
fasta_file = '/Users/liweihang/BT1051/Project2/2_/q2_purz0_filtered.fa'
output_csv_file = '/Users/liweihang/BT1051/Project2/2_/blast_results_with_updated_fasta.csv'

# Load the CSV file into a pandas DataFrame
df = pd.read_csv(csv_file)

# Read the FASTA file and create a set to store NCBI Accession identifiers
fasta_accessions = set()
with open(fasta_file, 'r') as f:
    lines = f.readlines()
    for i in range(0, len(lines), 2):  # FASTA format: every two lines
        accession = lines[i].strip()[1:]  # Remove '>' from the header
        fasta_accessions.add(accession)

# Filter the DataFrame to keep only rows with NCBI Accession in fasta_accessions
df_filtered = df[df['NCBI Accession'].isin(fasta_accessions)]

# Drop duplicates based on 'NCBI Accession' column to ensure uniqueness
df_filtered = df_filtered.drop_duplicates(subset=['NCBI Accession'])

# Save the updated DataFrame to a new CSV file
df_filtered.to_csv(output_csv_file, index=False)

print(f"Updated CSV file with unique and valid sequences has been saved at: {output_csv_file}")


```



##### （3） 下载 IMG/VR v4，使用本地 BLAST 的 makeblastdb 命令为 IMG/VR v4 建立索引。以（2）中用到的那条 PurZ0 序列作为查询序列，使用 BLASTp 搜索 IMG/VR v4 库，来获取库中所有的 PurZ0 序列（注意不要在结果中混入 PurA 或 PurZ）。你可以找到多少条？分别来自什么物种？提交一个 Excel 文件，表头为 NCBI Accession，物种，fasta 序列，E-value，bit score。 根据你找到的 PurZ0 的序列条数，简要评价NCBI nr 和 IMG/VR v4。

- 下载IMG/VR v4需要在IMG/VR上经过一系列较为繁琐的注册，之后在如下界面可以选择对应的Database下载到本地。

  ![7081742880274_.pic](/Users/liweihang/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/879268bfd3d932bb65a9a3371dbbb567/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/7081742880274_.pic.jpg)

  

  ```
  模板tr|A0A7L7SI10|A0A7L7SI10_9CAUD	IMGVR_UViG_2974748073_000001|2974748073|2974748122
  ```

  **搜库，利用和（2）一样的方法排除PurZ和PurA，之后**

  1. 输出比对后的序列的14S，243I和305D变更到哪一步：

  ```python
  from Bio import AlignIO
  
  alignment = AlignIO.read("final_aligned.fa", "fasta")
  
  # 找到模板序列
  template_id = "IMGVR_UViG_2974748073_000001"
  template_seq = None
  for record in alignment:
      if template_id in record.id:
          template_seq = str(record.seq)
          break
  
  if not template_seq:
      raise ValueError("Template sequence not found in alignment!")
  
  # 找到比对后的关键位置（S14, I243, D305）
  def find_aligned_pos(seq, unaligned_pos):
      """给定原始位置(1-based)返回比对后的位置(0-based)"""
      aa_count = 0
      for i, char in enumerate(seq):
          if char != '-':
              aa_count += 1
          if aa_count == unaligned_pos:
              return i
      return -1
  
  pos_S14 = find_aligned_pos(template_seq, 14)
  pos_I243 = find_aligned_pos(template_seq, 243)
  pos_D305 = find_aligned_pos(template_seq, 305)
  
  print(f"比对后的关键位置：S14={pos_S14}, I243={pos_I243}, D305={pos_D305}")
  ```

  Results：变化到：比对后的关键位置：S14=131, I243=706, D305=809。

  之后输出所有序列这三个氨基酸的位置，如果均为S，I，D则认为是PurZ0，否则剔除。

  ```python
  # 读取比对文件并提取所需位置的氨基酸，做判断后输出ID并统计保留与剔除的数量
  def extract_amino_acids(file_path, positions):
      with open(file_path, 'r') as f:
          lines = f.readlines()
      
      kept_ids = []
      discarded_ids = []
      seq = ""
      for line in lines:
          if line.startswith(">"):  # 处理ID行
              if seq:
                  # 处理之前的序列，提取位置
                  selected_aa = [seq[p - 1] if p <= len(seq) else '-' for p in positions]
                  # 判断这三个位置是否为 S, I, D
                  if all(aa in ['S', 'I', 'D'] for aa in selected_aa):
                      kept_ids.append(header)
                  else:
                      discarded_ids.append(header)
              # 获取新的ID
              header = line.strip().split()[0][1:]  # 获取序列的ID
              seq = ""  # 清空序列
          else:
              seq += line.strip()  # 将序列合并到一起
      
      # 处理最后一个序列
      if seq:
          selected_aa = [seq[p - 1] if p <= len(seq) else '-' for p in positions]
          # 判断这三个位置是否为 S, I, D
          if all(aa in ['S', 'I', 'D'] for aa in selected_aa):
              kept_ids.append(header)
          else:
              discarded_ids.append(header)
  
      return kept_ids, discarded_ids
  
  # 目标位置
  positions = [132, 707, 810]
  file_path = 'final_aligned.fa'
  
  # 获取结果
  kept_ids, discarded_ids = extract_amino_acids(file_path, positions)
  
  # 输出结果到txt文件
  with open('filtered_ids.txt', 'w') as output_file:
      output_file.write("Kept IDs:\n")
      for entry in kept_ids:
          output_file.write(f"{entry}\n")
      
      output_file.write("\nDiscarded IDs:\n")
      for entry in discarded_ids:
          output_file.write(f"{entry}\n")
  
  # 输出保留和剔除的数量
  print(f"Total kept IDs: {len(kept_ids)}")
  print(f"Total discarded IDs: {len(discarded_ids)}")
  
  ```

  ```
  Results：
  (base) liweihang@Mac-3 DB_IMGVR4 % /Users/liweihang/miniconda3/bin/python /Volumes/Elements/DB_IMGVR4/3_1.py
  Total kept IDs: 454
  Total discarded IDs: 47
  ```

  之后将这些ID去重，保留认为是PurZ0的序列

  ```python
  from Bio import SeqIO
  
  # 1. 读取 filtered_ids.txt 获取要保留的 ID
  with open("filtered_ids.txt", "r") as f:
      kept_ids = [line.strip() for line in f.readlines()[1:]]  # 跳过首行 "Kept IDs:"
  
  # 2. 过滤 potential_purz0.fa，仅保留匹配的序列
  input_fasta = "potential_purz0.fa"
  output_fasta = "purz0_filtered.fa"
  
  count = 0
  with open(output_fasta, "w") as out_f:
      for record in SeqIO.parse(input_fasta, "fasta"):
          if record.id in kept_ids:
              SeqIO.write(record, out_f, "fasta")
              count += 1
  
  print(f"已提取 {count} 条序列到 {output_fasta}")
  ```

  之后可以用IMG Genome ID来获取NCBI Assembly Accession和NCBI Genbank ID（注意上传的txt格式）

  ![截屏2025-03-26 14.59.39](/Users/liweihang/Library/Application Support/typora-user-images/截屏2025-03-26 15.01.54.png)

  下载想要的栏目：

![截屏2025-03-26 15.21.46](/Users/liweihang/Library/Application Support/typora-user-images/截屏2025-03-26 15.21.46.png)

导出上述文件，与之前的结果合并即可。保存为文件3提交。



**简要评价NCBI nr和IMG/VR v4：**尽管nr库比IMG/VR v4大得多，但是从找到序列的条数来看竟然只有后者的一半不到，说明IMG/VR v4还是收集许多不在nr库中的宝贵数据的。



**（4） 对于（2）和（3）中找到的所有的 PurZ0 序列，使用 mafft 工具分别做多序列比对。在云桌面本地安装 hmmer3， 使用 hmmer3 中的 hmmbuild 工具，为两个多序列比对生成 profile hmm 并使用 Skylign （http://skylign.org/）来获得这两个 hmm 文件的可视化结果。提交名为 PurZ0_nr_hmm 和 PurZ0_imgvr4_hmm 可视化结果图片。比较这两个图片，你可以得出什么结论？**

- 安装hmmer3

  ```bash
  conda install bioconda:hmmer
  ```

1. mafft序列比对：

   ```bash
   (BT1051) liweihang@Mac-3 4_ % mafft --auto PurZ0_nrdb.fasta > AlignedPurZ0_nrdb.fasta
   (BT1051) liweihang@Mac-3 4_ % mafft --auto Purz0_IMGVRv4.fa >AlignedPurz0_IMGVRv4.fa
   ```

2. Hmmhuild生成profile hmm

   ```bash
   hmmbuild PurZ0_nr_hmm AlignedPurZ0_nrdb.fasta
   hmmbuild PurZ0_imgvr4_hmm AlignedPurz0_IMGVRv4.fa
   ```

   ![文件4_PurZ0_nr_hmm](/Users/liweihang/BT1051/Project2/文件4_PurZ0_nr_hmm.png)

   

   ![文件4_PurZ0_imgvr4_hmm](/Users/liweihang/BT1051/Project2/文件4_PurZ0_imgvr4_hmm.png)
   
   - **结论：**两者的结果还是有相同之处，可以看到计算出来的保守残基是较为类似的。

**（5） 对于（2）中找到的所有的 PurZ0 序列，先使用 cdhit 工具以 80% seqid 进行压缩，使用压缩后的序列文件重复（4）的所有操作。提交名为 PurZ0_nr_hmm_cdhit0.8可视化结果图片。比较 PurZ0_nr_hmm 和 PurZ0_nr_hmm_cdhit0.8，你有什么结论？**

将找到的PurZ0序列整合,并用 cdhit 工具以 80% seqid 进行压缩：

```bash
cat PurZ0_nrdb.fasta Purz0_IMGVRv4.fa > PurZ0_All.fasta
awk '/^>/{if(!seen[$0]++){print}} !/^>/' PurZ0_All.fasta > Filtered——PurZ0_All.fasta #去掉重复序列
cd-hit -i Filtered_PurZ0_All.fasta -o PurZ0_nr_cdhit0.8.fasta -c 0.8 -n 5
mafft --auto PurZ0_nr_cdhit0.8.fasta > Aligned_PurZ0_nr_cdhit0.8.fasta
hmmbuild PurZ0_nr_hmm_cdhit0.8 Aligned_PurZ0_nr_cdhit0.8.fasta
```

![文件5_PurZ0_nr_hmm_cdhit0.8](/Users/liweihang/BT1051/Project2/文件5_PurZ0_nr_hmm_cdhit0.8.png)

- 比较 PurZ0_nr_hmm 和 PurZ0_nr_hmm_cdhit0.8得出的结论：从两者的LOGO图来看，经过 80% seqid，保守的氨基酸在图像中更突出，图像“比较干净”，更容易被观察到，可能是因为CD-HIT 通过聚类减少了相似度高于 80% 的序列，使得 LOGO 图中的变异性降低，这样一来，剩下的序列在对齐后，保守位点的相对频率上升，导致 LOGO 图的高度（信息含量）增加。

 

**（6） 在 PurA.fasta 中选一条 PurA 作为查询序列，使用本地安装的 BLASTp 搜索 nr 库，使用输出结果的前 300 条，用 cdhit 以 80% seqid 进行压缩，用压缩后的序列文件重复（4）的所有操作。提交名为 PurA_nr_hmm_cdhit0.8 的可视化结果图片。对 PurZ0_nr_hmm_cdhit0.8 和 PurA_nr_hmm_cdhit0.8，分别标出底物结合口袋残基的位置，比较两者的异同。提交标记好的图片。**

选择序列：Seleted_PurA.fa:

```
>sp|P0A7D4|PURA_ECOLI Adenylosuccinate synthetase OS=Escherichia coli (strain K12) OX=83333 GN=purA PE=1 SV=2
MGNNVVVLGTQWGDEGKGKIVDLLTERAKYVVRYQGGHNAGHTLVINGEKTVLHLIPSGI
LRENVTSIIGNGVVLSPAALMKEMKELEDRGIPVRERLLLSEACPLILDYHVALDNAREK
ARGAKAIGTTGRGIGPAYEDKVARRGLRVGDLFDKETFAEKLKEVMEYHNFQLVNYYKAE
AVDYQKVLDDTMAVADILTSMVVDVSDLLDQARQRGDFVMFEGAQGTLLDIDHGTYPYVT
SSNTTAGGVATGSGLGPRYVDYVLGILKAYSTRVGAGPFPTELFDETGEFLCKQGNEFGA
TTGRRRRTGWLDTVAVRRAVQLNSLSGFCLTKLDVLDGLKEVKLCVAYRMPDGREVTTTP
LAADDWKGVEPIYETMPGWSESTFGVKDRSGLPQAALNYIKRIEELTGVPIDIISTGPDR
TETMILRDPFDA
```

比对，并提取比对结果：

```bash
blastp -query Seleted_PurA.fa -db /share/database/ncbi_nr/nr -out q6_blast_results.txt -evalue 1e-5 -num_threads 10 -outfmt "6 sacc staxid qcovs pident evalue bitscore sseq"
awk '{print ">" $1 "\n" $7}' q6_blast_results.txt > PurA_nrdb.fasta #提取所有的序列
awk 'NR<=300 {print ">"$1"\n"$NF}' q6_blast_results.txt > PurAsequences_300.fasta #提取前300条序列

```

重复（4）中的操作：

```bash
cd-hit -i /Users/liweihang/BT1051/Project2/6_/PurAsequences_300.fasta \
-o /Users/liweihang/BT1051/Project2/6_/PurAsequences_300_cdhit80.fasta \
-c 0.80 -n 5 -M 2000 -T 4

mafft --auto /Users/liweihang/BT1051/Project2/6_/PurAsequences_300_cdhit80.fasta \
> /Users/liweihang/BT1051/Project2/6_/PurA_msa.fasta

hmmbuild /Users/liweihang/BT1051/Project2/6_/PurA.hmm /Users/liweihang/BT1051/Project2/6_/PurA_msa.fasta
```

PurA_nr_hmm_cdhit0.8 的可视化结果图片:

![文件5_PurA_nr_hmm_cdhit0.8](/Users/liweihang/BT1051/Project2/文件5_PurA_nr_hmm_cdhit0.8.png)



PurZ0_nr_hmm_cdhit0.8 和 PurA_nr_hmm_cdhit0.8，底物结合口袋残基的位置:

根据文献：Nat Microbiol. 2023 Jul;8(7):1330-1338.:

PurZ0的底物结合口袋残基为：Serine15, Isoleucine 244, Aspartic Acid 306 （以下结果截图自Skylign）

![](/Users/liweihang/BT1051/Project2/6_/PurZ0KeyAA_Skylign/PurZ0_serine.png)

![](/Users/liweihang/BT1051/Project2/6_/PurZ0KeyAA_Skylign/PurZ0_Isoleucine.png)

![](/Users/liweihang/BT1051/Project2/6_/PurZ0KeyAA_Skylign/PurZ0_AsparticAcid.png)

PurA的底物结合口袋残基为：Aspartic Acid 13, Threonine 271, Aspartic Acid 333

![](/Users/liweihang/BT1051/Project2/6_/PurAKeyAA_Skylign/PurA_AsparticAcid1.png)

![](/Users/liweihang/BT1051/Project2/6_/PurAKeyAA_Skylign/PurA_Threonine.png)

![](/Users/liweihang/BT1051/Project2/6_/PurAKeyAA_Skylign/PurA_AsparticAcid2.png)

**（7）对于 IMG/VR v4 数据库，使用 jackhmmer 进行搜索其中的 PurZ0，和（3）中 BLASTp的结果进行比较。提交搜索命令和搜索结果。**

Command:

```bash
jackhmmer -N 5 -o q7_jackhmm.out -A q7_jackhmm.aln --tblout q7_jackhmm.hits --domtblout q7_jackhmm.domtblout  Seleted_PurZ0.fa /Volumes/Elements/DB_IMGVR4/protein_hc.fna

-N 5：设置 jackhmmer 运行 5 轮迭代。
--tblout jackhmmer_PurZ0_results.txt：将结果以表格形式存入文件。
--cpu 4：使用 4 个 CPU 线程
Seleted_PurZ0.fa：输入的查询序列
/Volumes/Elements/DB_IMGVR4/protein_hc.fna：目标数据库（IMG/VR v4）。

Note: 上述命令适合较小的数据库,数据库过大会报错，需要对数据库进行拆分。

安装seqkit来分析，拆分库：
conda install seqkit     
seqkit stats /Volumes/Elements/DB_IMGVR4/protein_hc.fna #查看库的信息：
(BT1051) liweihang@Mac-3 jackhmmer_temp % seqkit stats /Volumes/Elements/DB_IMGVR4/protein_hc.fna
file           format      type     num_seqs      sum_len      min_len  avg_len  max_len
protein_hc.fna  FASTA   Protein    112,568,966  25,622,016,064     1     227.6   512,011

seqkit split /Volumes/Elements/DB_IMGVR4/protein_hc.fna -s 1000000 -O split_db -f #按照1000000seq/file拆分

批量读取，并合并：
#!/bin/bash

# 定义路径
BASE_DIR="/Users/liweihang/BT1051/Project2/7_"
DB_DIR="$BASE_DIR/split_db"
QUERY_FILE="$BASE_DIR/Seleted_PurZ0.fa"

# 确保结果存放的目录存在
mkdir -p "$BASE_DIR/results_combined"

# 遍历拆分后的数据库文件
for FILE in "$DB_DIR"/protein_hc.part_*.fna; do
    # 获取文件编号 (001, 002, ..., 113)
    FILE_NUM=$(basename "$FILE" | grep -oE '[0-9]+')

    # 创建单独的目录存放结果
    RESULT_DIR="$BASE_DIR/result_${FILE_NUM}"
    mkdir -p "$RESULT_DIR"

    # 运行 jackhmmer 并将结果存入对应目录
    jackhmmer -N 5 \
        -o "$RESULT_DIR/q7_jackhmm.out" \
        -A "$RESULT_DIR/q7_jackhmm.aln" \
        --tblout "$RESULT_DIR/q7_jackhmm.hits" \
        --domtblout "$RESULT_DIR/q7_jackhmm.domtblout" \
        "$QUERY_FILE" "$FILE"

    echo "Finished processing $FILE, results stored in $RESULT_DIR"
done

# 合并所有结果
cat "$BASE_DIR"/result_*/q7_jackhmm.hits > "$BASE_DIR/results_combined/q7_jackhmm_all.hits"
cat "$BASE_DIR"/result_*/q7_jackhmm.domtblout > "$BASE_DIR/results_combined/q7_jackhmm_all.domtblout"

echo "All results combined in $BASE_DIR/results_combined/"

```

```python
#画维恩图比较：
import matplotlib.pyplot as plt
from matplotlib_venn import venn2

# 读取文件并提取 IMGVR_UViG ID
def extract_ids(filename, column_index):
    ids = set()
    with open(filename, "r") as file:
        for line in file:
            if line.startswith("#"):
                continue
            parts = line.strip().split()
            if len(parts) > column_index:
                imgvr_id = parts[column_index].split("|")[0]  # 取IMGVR_UViG部分
                ids.add(imgvr_id)
    return ids

# 提取ID
blast_ids = extract_ids("blast_parsed.txt", 1)
jackhmmer_ids = extract_ids("jackhmmer_parsed.txt", 0)

# 统计数量
only_blast = len(blast_ids - jackhmmer_ids)
only_jackhmmer = len(jackhmmer_ids - blast_ids)
both = len(blast_ids & jackhmmer_ids)

# 绘制维恩图
plt.figure(figsize=(6, 6))
venn2([blast_ids, jackhmmer_ids], set_labels=("BLASTp", "Jackhmmer"))
plt.title("Comparison of BLASTp and Jackhmmer Results")
plt.show()

# 打印统计信息
print(f"BLASTp 结果数量: {len(blast_ids)}")
print(f"Jackhmmer 结果数量: {len(jackhmmer_ids)}")
print(f"共同的 IMGVR_UViG ID 数量: {both}")

```

![](/Users/liweihang/BT1051/Project2/文件7_VennComparision.png)

可以看到jackhammer的敏感性远大于普通的BLASTp.

**（8）还有哪些方法可以用来搜索 IMG/VR v4 数据库中的 PurZ0？尝试选取一种，并提交搜索命令和搜索结果。这种方法和 BLASTp 以及 jackhmmer 有什么不同？**

方法：mmseq2;  HHblits等，这里选择diamond

Command:

```bash
conda install diamond
diamond makedb --in /Volumes/Elements/DB_IMGVR4/protein_hc.fna \
               --db /Volumes/Elements/Diamond/protein_hc_db \
               --threads 8
 diamond blastp \
    --db /Volumes/Elements/Diamond/protein_hc_db.dmnd \
    --query /Users/liweihang/BT1051/Project2/8_/Seleted_PurZ0.fa \
    --out /Users/liweihang/BT1051/Project2/8_/diamond_search_result.txt \
    --outfmt 6 \
    --evalue 1e-5 \
    --max-target-seqs 500 \
    --threads 8

```

结果已经存放为diamond_search_result.txt.

结果一览：

![截屏2025-03-28 00.36.29](/Users/liweihang/Library/Application Support/typora-user-images/截屏2025-03-28 00.36.29.png)

不同：速度大大加快（无论是建库的速度还是搜库的速度都有显著提升）
